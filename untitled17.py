# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15py74PBBquUNW_9bxPbrN9q_DEnxxvWw
"""

import tensorflow as tf
import matplotlib.pyplot as plt

from keras.models import Sequential
from keras.layers import Dense,Activation,AlphaDropout
from keras.optimizers import Adam

mnist=tf.keras.datasets.mnist
(xtrain,ytrain),(xtest,ytest)=mnist.load_data()
xtrain,xtest=(xtrain/255.0),(xtest/255.0)

models=tf.keras.models.Sequential([
       tf.keras.layers.Flatten(input_shape=(28,28)),
       tf.keras.layers.Dense(512,activation='relu'),
       tf.keras.layers.Dropout(0,2),
       tf.keras.layers.Dense(10,activation='softmax')
])

models.compile(optimizer='SGD',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

tf.callbacks=tf.keras.callbacks.TensorBoard(log_dir='logs/fit',histogram_freq=1)

history=models.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=10,callbacks=tf.callbacks)

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard

tensorboard --logdir logs/fit

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.legend(['train','test'],loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train','test'],loc='upper left')
plt.show()